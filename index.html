<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <link rel="stylesheet" href="style.css">
    <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Open+Sans"/>
    <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Rock+Salt"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <title>Documentation</title>
</head>
<body>

<nav id="navbar">
    <header>Machine Learning</header>
    <ul>
        <li><a class="nav-link" href="#Introduction">Introduction</a></li>
        <li><a class="nav-link" href="#Data_Exploration">Data Exploration</a></li>
        <li><a class="nav-link" href="#Machine_Learning_Models">Machine Learning Models</a></li>
        <li><a class="nav-link" href="#Model_Validation">Model Validation</a></li>
        <li><a class="nav-link" href="#Underfitting_and_Overfitting">Underfitting and Overfitting</a></li>
        <li><a class="nav-link" href="#Reference">Reference</a></li>
    </ul>
</nav>

<main id="main-doc">

    <section class="main-section" id="Introduction">
        <header>
            Introduction
        </header>
        <article>
            <p>The content on this page is based on the <a href="https://www.kaggle.com/learn/intro-to-machine-learning">Machine
                Learning Micro-Course</a> from <a href="https://www.kaggle.com">Kaggle</a> and will summarise the
                content from the lessons.</p>
            <p>Machine Learning models aim to describe data. An example of a model is a Decision Tree. This splits
                the data into categories for example, to predict house prices the data can be split based on whether the
                house has more or less than X bedrooms.
            </p>
            <quote>The step of capturing patterns from data is called <strong>fitting</strong> or <strong>training</strong>
                the model. The data used to <strong>fit</strong> the model is called the <strong>training data.</strong></quote>
            <p>Once the model has been fit it can be applied to new data to predict house values.</p>
        </article>
    </section>

    <section class="main-section" id="Data_Exploration">
        <header>
            Data Exploration
        </header>
        <article>
            <p>To get started, it is important to understand the data.
                Pandas is the primary tool used for exploring and manipulating data.</p>
            <p>To explore the data, Pandas DataFrames are used. The following will load and give a summary of the data.</p>
    <code>import pandas as pd
# save filepath to variable for easier access
melbourne_file_path = '../input/melbourne-housing-snapshot/melb_data.csv'
# read the data and store data in DataFrame titled melbourne_data
melbourne_data = pd.read_csv(melbourne_file_path)
# print a summary of the data in Melbourne data
melbourne_data.describe()</code>
        </article>
    </section>

    <section class="main-section" id="Machine_Learning_Models">
        <header>
            Machine Learning Models
        </header>
        <article>
            <p>To further explore the data it can be useful can print the list of all columns in the dataset.
            </p>
            <p>When setting up a model the target needs to be defined. In the house price example, the target value
            is the price. This is commonly defined as <strong>y</strong>.</p>
            <code>y = melbourne_data.Price</code>
            <p>The columns used to input to the model and later to make predictions are referred to as features. In the
            house prices example, this could be the number of bedrooms, location, size. These features can be selected
            with the following and are conventionally referred to as <strong>X</strong>.</p>
            <code>melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude']</code>
            <p>Scikit-learn, written as sklearn, is the most popular python library for modelling data from DataFrames.
                The steps to build and use a model are:</p>
            <ul>
            <li>Define the model</li>
            <li>Fit the data</li>
            <li>Predict based on new data</li>
            <li>Evaluate the model</li>
        </ul>
        <p>Using the following code a decision tree model is defined, the data are fit with the features and target
        variable and predictions are made.</p>
            <code>from sklearn.tree import DecisionTreeRegressor

# Define model. Specify a number for random_state to ensure same results each run
melbourne_model = DecisionTreeRegressor(random_state=1)

# Fit model
melbourne_model.fit(X, y)

print("Making predictions for the following 5 houses:")
print(X.head())
print("The predictions are")
print(melbourne_model.predict(X.head()))</code>
        </article>
    </section>

    <section class="main-section" id="Model_Validation">
        <header>
            Model Validation
        </header>
        <article>
            <p>In the previous section a model was built, next it needs to be evaluated!</p>
            <p>A useful measurement for model quality is predictive accuracy, whether the predictions were close to their true values.
            Predictions need to be made on a different dataset to the one that the model was trained on.</p>
            <p>To summarise model quality <strong>Mean Absolute Error (MAE)</strong> can be used. The error can be defined as:</p>
            <code>error = actual - predicted</code>
            <p>The MAE takes the absolute value of each error and takes the average of the absolute error and can be described as</p>
            <quote>On average, our predictions are off by about X</quote>
            <p>Continuing using the model from the previous section, the MAE is calculated by:</p>
            <code>from sklearn.metrics import mean_absolute_error
predicted_home_prices = melbourne_model.predict(X)
mean_absolute_error(y, predicted_home_prices)</code>
            <p>This example however uses a single sample for both building the model and evaluating which can create biases in the model,
                and lead to inaccuracies when applying the model to new data.
            It it preferred to split the sample into <i>training data</i> and <i>validation data</i> (or test data).
            This can be done with sklearn:</p>
            <code>from sklearn.model_selection import train_test_split

# split data into training and validation data, for both features and target
# The split is based on a random number generator. Supplying a numeric value to
# the random_state argument guarantees we get the same split every time we
# run this script.
train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)
# Define model
melbourne_model = DecisionTreeRegressor()
# Fit model
melbourne_model.fit(train_X, train_y)

# get predicted prices on validation data
val_predictions = melbourne_model.predict(val_X)
print(mean_absolute_error(val_y, val_predictions))</code>
            <p>The value of the MAE may significantly increase when tested on validation data instead of the full sample - this is to be expected.</p>
        </article>
    </section>

    <section class="main-section" id="Underfitting_and_Overfitting">
        <header>
            Underfitting and Overfitting
        </header>
        <article>
            <p>To find the optimal model either the parameters of a model can be changed or a different model can be tested.</p>
            <p>If a model is <strong>overfit</strong>, it captures spurious patterns in the training data that won't reoccur in the future.
            Alternatively a model is <strong>underfit</strong> if the model does not capture relevant patterns.
            In both of these cases the predictions will be less accurate, another reason to train and predict on different datasets.
            </p>
            <p>Using the Decision Tree model, the model is trained with different values for the <i>max_leaf_nodes</i> parameter
                to determine the MAE:</p>
            <code>from sklearn.metrics import mean_absolute_error
from sklearn.tree import DecisionTreeRegressor

def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):
    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)
    model.fit(train_X, train_y)
    preds_val = model.predict(val_X)
    mae = mean_absolute_error(val_y, preds_val)
    return(mae)</code>
            <p>Using the same data from the previous section, the accuracy of the models with different parameters can be compared:</p>
            <code># compare MAE with differing values of max_leaf_nodes
for max_leaf_nodes in [5, 50, 500, 5000]:
    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)
    print("Max leaf nodes: %d  \t\t Mean Absolute Error:  %d" %(max_leaf_nodes, my_mae))
            </code>

        </article>
    </section>

    <section class="main-section" id="Reference">
        <header>
            Reference
        </header>
        <article>
            <p>Documentation on this page is based on <a href="https://www.kaggle.com/learn/intro-to-machine-learning">Kaggle ML microcourse</a></p>
        </article>
    </section>

    <div class="footer">
        <div id="contact">
            <a id="github" href="https://github.com/kaparker" target="_blank"><i class="fa fa-github fa-2x"></i></a>
            <a id="twitter" href="https://twitter.com/_kaparker" target="_blank"><i class="fa fa-twitter fa-2x"></i></a>
            <a id="linkedin" href="https://www.linkedin.com/in/kerryaparker" target="_blank"><i
                    class="fa fa-linkedin fa-2x"></i></a>
        </div>
        <h3>Created by Kerry</h3>
        <p id="footer-details">for the <a
                href="https://learn.freecodecamp.org/responsive-web-design/responsive-web-design-projects/build-a-technical-documentation-page/">FCC
            technical documentation tutorial</a></p>
    </div>

</main>



</body>
</html>